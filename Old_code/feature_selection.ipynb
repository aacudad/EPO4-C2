{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from scipy import signal\n",
    "# import neurokit2 as nk\n",
    "import random\n",
    "# %matplotlib inline \n",
    "import pyhrv\n",
    "import ipynb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "def pca_feat(features):\n",
    "    scaler = StandardScaler().fit(features)\n",
    "    X_train = scaler.transform(features)\n",
    "\n",
    "    pca = PCA(n_components=25)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    x_train = X_train_pca[:,0:3] # Three best features\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Variance Threshold\n",
    "def var_thres(features):\n",
    "    scaler = MinMaxScaler().fit(total_features)\n",
    "    X_train = scaler.transform(total_features)\n",
    "\n",
    "    X = X_train[0:,0:49]\n",
    "\n",
    "    v_threshold = VarianceThreshold(threshold=0.005) # Set a threshold\n",
    "    v_threshold.fit(X)\n",
    "    index = v_threshold.get_support()\n",
    "    true_index = [i for i, x in enumerate(index) if x]\n",
    "    vt_features = [total_features_index[i] for i in true_index]\n",
    "    return vt_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_selector(X, y,num_feats):\n",
    "    cor_list = []\n",
    "    feature_name = X.columns.tolist()\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature\n",
    "\n",
    "def pears(X):\n",
    "    cor_support, cor_feature = cor_selector(X, y,6)\n",
    "    return cor_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(features)\n",
    "X_train = scaler.transform(features)\n",
    "\n",
    "pca = PCA(n_components=25)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "x_train = X_train_pca[:,0:3] # Three best features\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x_train[:,0], x_train[:,1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform pca on features\n",
    "plt.bar(range(0,25), pca.explained_variance_ratio_, label=\"individual var\");\n",
    "plt.step(range(0,25), np.cumsum(pca.explained_variance_ratio_),'r', label=\"cumulative var\");\n",
    "plt.xlabel('Principal component index'); plt.ylabel('explained variance ratio %');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information gain\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "%matplotlib inline\n",
    "\n",
    "scaler = StandardScaler().fit(features)\n",
    "X_train = scaler.transform(features)\n",
    "\n",
    "importances = mutual_info_classif(X_train, y)\n",
    "feat_importances = pd.Series(importances, features.columns[0:len(features.columns)])\n",
    "feat_importances.plot(kind='bar', color='teal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_features_index = []\n",
    "\n",
    "for a in total_features:\n",
    "    total_features_index.append(a)\n",
    "\n",
    "print(total_features_index)\n",
    "print(len(total_features_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Threshold\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler().fit(total_features)\n",
    "X_train = scaler.transform(total_features)\n",
    "\n",
    "X = X_train[0:,0:49]\n",
    "\n",
    "v_threshold = VarianceThreshold(threshold=0.005) # Set a threshold\n",
    "v_threshold.fit(X)\n",
    "print(v_threshold.variances_)\n",
    "index = v_threshold.get_support()\n",
    "print(index)\n",
    "true_index = [i for i, x in enumerate(index) if x]\n",
    "\n",
    "# for i in true_index:\n",
    "#     print(total_features_index[i])\n",
    "#     print(total_features[total_features_index[i]])\n",
    "vt_features = [total_features_index[i] for i in true_index]\n",
    "len(vt_features)\n",
    "# features = total_features[vt_features]\n",
    "# features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson Correlation\n",
    "import seaborn as sns\n",
    "\n",
    "# total_features = pd.merge(edafeatures, ecgfeatures, left_index=True, right_index=True)\n",
    "out_features = total_features\n",
    "out_features['y'] = y\n",
    "\n",
    "# plt.figure(figsize=(12,10))\n",
    "cor = out_features.corr()\n",
    "# print(cor)\n",
    "# sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "# plt.show()\n",
    "#Correlation with output variable\n",
    "cor_target = abs(cor[\"y\"])\n",
    "\n",
    "# print(cor_target)\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.3]\n",
    "# features = out_features[relevant_features.index[:-1]]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HR_mean, scr_mobility scr_integral \n",
    "print(out_features[['HR_mean',\"scr_mobility\"]].corr())\n",
    "print(out_features[[\"HR_mean\",\"scr_integral\"]].corr())\n",
    "print(out_features[[\"scr_mobility\",\"scr_integral\"]].corr())\n",
    "# features = features[['HR_mean',\"scr_mobility\",\"scr_integral\"]]\n",
    "features = out_features[[\"HR_mean\", \"scr_mobility\", \"scr_integral\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features\n",
    "def cor_selector(X, y,num_feats):\n",
    "    cor_list = []\n",
    "    feature_name = X.columns.tolist()\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature\n",
    "cor_support, cor_feature = cor_selector(X, y,6)\n",
    "print(str((cor_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi-squared\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X=features\n",
    "X_norm = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "chi_selector = SelectKBest(chi2, k=6)\n",
    "chi_selector.fit(X_norm, y)\n",
    "chi_support = chi_selector.get_support()\n",
    "chi_feature = X.loc[:,chi_support].columns.tolist()\n",
    "print(str(chi_feature), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Forward wrapper\n",
    "\n",
    "# from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "# ffs = SequentialFeatureSelector(total_features, k_features='best', forward = 'True', n_jobs=-1)\n",
    "# ffs.fit(X, y)\n",
    "# features= list(ffs.k_feature_names_)\n",
    "# features= list(map(int, features))\n",
    "# lr.fit[x_train[features], y_train]\n",
    "# y_pred = lr.predict(x_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backwards\n",
    "import statsmodels.api as sm\n",
    "\n",
    "cols = list(total_features.columns)\n",
    "pmax = 1\n",
    "\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = total_features[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)\n",
    "features = total_features[selected_features_BE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper Forwards\n",
    "sfs = SFS(svm.SVC(),\n",
    "          k_features=6,\n",
    "          forward=True,\n",
    "          floating=False,\n",
    "          scoring = 'r2',\n",
    "          cv = 0)\n",
    "sfs.fit(X, y)\n",
    "fwrapper_feature = list(sfs.k_feature_names_)\n",
    "fwrapper_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper Backwards\n",
    "sbs = SFS(svm.SVC(),\n",
    "         k_features=6,\n",
    "         forward=False,\n",
    "         floating=False,\n",
    "         cv=0)\n",
    "sbs.fit(X, y)\n",
    "bwrapper_feature = list(sbs.k_feature_names_)\n",
    "bwrapper_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step-wise wrapper\n",
    "sffs = SFS(svm.SVC(),\n",
    "         k_features=(3,11),\n",
    "         forward=True,\n",
    "         floating=True,\n",
    "         cv=0)\n",
    "sffs.fit(X, y)\n",
    "swrapper_feature = list(sffs.k_feature_names_)\n",
    "swrapper_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "fig1 = plot_sfs(sfs.get_metric_dict(), kind='std_dev')\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = total_features[feature_namess]\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = features\n",
    "alphas = np.logspace(-4, -0.5, 5)\n",
    "\n",
    "out_k_fold = KFold(3, shuffle=False)\n",
    "in_k_fold = KFold(3, shuffle=False)\n",
    "for (calib, test) in out_k_fold.split(X, y):\n",
    "    X_calib, y_calib = X[calib[0]:calib[-1]], y[calib[0]:calib[-1]]\n",
    "    X_test, y_test = X[test[0]:test[-1]], y[test[0]:test[-1]]\n",
    "    lasso_cv = LassoCV(alphas=alphas, random_state=0, max_iter=10000, cv=in_k_fold)\n",
    "    lasso_cv.fit(X_calib, y_calib)\n",
    "    print(lasso_cv.alpha_, lasso_cv.score(X_test, y_test))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sel_ = SelectFromModel(\n",
    "    LogisticRegression(C=0.5, penalty='l1', solver='liblinear', random_state=10))\n",
    "sel_.fit(scaler.transform(X_train), y_train)\n",
    "\n",
    "a =(sel_.estimator_.coef_ == 0).ravel().tolist()\n",
    "\n",
    "# removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "X_train_selected = sel_.transform(scaler.transform(X_train))\n",
    "X_test_selected = sel_.transform(scaler.transform(X_test))\n",
    "# selected_columns_lasso = logistic.columns[selected_featuress.var() != 0]\n",
    "\n",
    "# Y_test_pred = logistic_model.predict(X_test)\n",
    "# log_score = logistic_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "num_feats = 10\n",
    "scaler = StandardScaler().fit(features)\n",
    "X_train = scaler.transform(features)\n",
    "embeded_lr_selector = SelectFromModel(LogisticRegression(C=1, penalty=\"l1\", solver='liblinear'), max_features=num_feats)\n",
    "embeded_lr_selector.fit(scaler.transform(X_train), y)\n",
    "\n",
    "embeded_lr_support = embeded_lr_selector.get_support()\n",
    "embeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\n",
    "print(str((embeded_lr_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "scaler = StandardScaler().fit(total_features)\n",
    "X_train = scaler.transform(total_features)\n",
    "\n",
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), max_features=10)\n",
    "embeded_rf_selector.fit(X_train, y)\n",
    "\n",
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str((embeded_rf_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbc=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
    "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
    "\n",
    "embeded_lgb_selector = SelectFromModel(lgbc, max_features=num_feats)\n",
    "embeded_lgb_selector.fit(X, y)\n",
    "\n",
    "embeded_lgb_support = embeded_lgb_selector.get_support()\n",
    "embeded_lgb_feature = X.loc[:,embeded_lgb_support].columns.tolist()\n",
    "print(str(len(embeded_lgb_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "scaler = StandardScaler().fit(total_features)\n",
    "X_train = scaler.transform(total_features)\n",
    "\n",
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), max_features=10)\n",
    "embeded_rf_selector.fit(X_train, y)\n",
    "\n",
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str((embeded_rf_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = total_features[embeded_rf_feature]\n",
    "x_train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
