{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import butter, iirnotch, lfilter\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "import pandas as pd\n",
    "from ecgdetectors import Detectors\n",
    "import pyhrv.frequency_domain as fd\n",
    "import pyhrv.time_domain as td\n",
    "import pyhrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set up an empty features file\n",
    "# df_features = pd.DataFrame(None, columns= ['feat_nn20', 'feat_nn50', 'feat_rmssd', 'feat_nnhr', \n",
    "#                                      'feat_sdsd', 'feat_pnn50', 'feat_pnn20', 'peak vlf', 'peak lf','peak hf', 'norm power lf', \n",
    "#                                      'norm power hf', 'power ratio', 'total power'])\n",
    "# #print(df_features)\n",
    "# write_to_csv(df_features, \"out_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that reads a csv file and outputs a data frame\n",
    "def read_from_csv(file):\n",
    "    data_frame = pd.read_csv(file, sep=\",\")\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that writes a data frame to a csv file\n",
    "def write_to_csv(df, file):\n",
    "    df.to_csv(index=False)\n",
    "    location = \"C:/Users/riche/OneDrive/Documenten/Github/EPO4-C2/\"\n",
    "    path = location + file\n",
    "    os.makedirs(location, exist_ok=True)  \n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering\n",
    "def filter_ecgsignal(ecg, fs):\n",
    "    ecg_td = td.ecg(ecg, interactive= False, show = False, sampling_rate=700)\n",
    "    filtered_ecg = ecg_td['filtered']\n",
    "    # nyq = 0.5*fs\n",
    "    # order=5\n",
    "\n",
    "    # # highpass filter\n",
    "    # high=0.5\n",
    "    # high= high/nyq\n",
    "    # b, a = butter(order, high, 'highpass')\n",
    "    # ecg_h = lfilter(b,a,ecg)\n",
    "\n",
    "    # # lowpass filter\n",
    "    # low = 70\n",
    "    # low= low/nyq\n",
    "    # b, a = butter(order, low, 'lowpass')\n",
    "    # ecg_hl = lfilter(b,a,ecg_h)\n",
    "\n",
    "    # # notch filter\n",
    "    # notch=50\n",
    "    # notch = notch/nyq\n",
    "    # b, a = iirnotch(notch, 30, fs)\n",
    "    # ecg_hln = lfilter(b,a,ecg_hl)\n",
    "\n",
    "    # t=np.arange(0,ecg.size*(1/fs),(1/fs))\n",
    "    # t=t[:ecg.size]\n",
    "\n",
    "    # plt.figure(figsize=(12,4))\n",
    "    # plt.plot(t,ecg,label=\"raw ECG\")\n",
    "    # plt.plot(t,ecg_hln, label=\"filtered ECG\")\n",
    "    # plt.xlabel('$Time (s)$') \n",
    "    # plt.ylabel('$ECG$') \n",
    "    # plt.legend()\n",
    "    return filtered_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect R-peaks\n",
    "def detect_rpeaks(fs, ecg):\n",
    "    ecg_td = td.ecg(ecg, interactive= False, show = False, sampling_rate=700)\n",
    "    rpeaks = ecg_td['rpeaks']\n",
    "    # detectors = Detectors(fs)\n",
    "\n",
    "    # r_peaks_pan = detectors.pan_tompkins_detector(ecg_hln)\n",
    "    # r_peaks_pan = np.asarray(r_peaks_pan)\n",
    "\n",
    "    # plt.figure(figsize=(12,4))\n",
    "    # plt.plot(ecg_hln)\n",
    "    # plt.plot(r_peaks_pan,ecg_hln[r_peaks_pan], 'ro')\n",
    "    return rpeaks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hrv import HRV   # to import the module\n",
    "\n",
    "# Feature extraction\n",
    "def get_features(r_peaks_pan, fs, df, index):\n",
    "    features = []\n",
    "    ecg_fft = fd.frequency_domain(rpeaks = r_peaks_pan, show = False)\n",
    "    plt.close(ecg_fft[\"ar_plot\"])\n",
    "    plt.close(ecg_fft[\"lomb_plot\"])\n",
    "    plt.close(ecg_fft[\"fft_plot\"])\n",
    "    hrv_class = HRV(fs)\n",
    "    # print(r_peaks_pan)\n",
    "    #Number of pairs of succesive NNs that differ by more than 20ms(NN20)\n",
    "    features.append(hrv_class.NN20(r_peaks_pan))\n",
    "    # print(f\"nn20:{feat_nn20}\")\n",
    "    #Number of pairs of succesive NNs that differ by more than 50ms(NN50)\n",
    "    features.append(hrv_class.NN50(r_peaks_pan))\n",
    "    # print(f\"nn50:{feat_nn50}\")\n",
    "    #Root mean square of succesive differences(RMSSD)\n",
    "    features.append(hrv_class.RMSSD(r_peaks_pan, normalise= True))\n",
    "    # print(f\"rmssd:{feat_rmssd}\")\n",
    "    #Heart-rate feature extraction in BPM(HR)\n",
    "    features.append(np.mean(hrv_class.HR(r_peaks_pan)))\n",
    "    # print(f\"HR:{feat_hr}\")\n",
    "    #Standard deviation of succesive differences(SDSD)\n",
    "    features.append(hrv_class.SDSD(r_peaks_pan))\n",
    "    # print(f\"SDSD:{feat_sdsd}\")\n",
    "    #The proportion of NN50 divided by total number of NNs(pNN50)\n",
    "    features.append(hrv_class.pNN50(r_peaks_pan))\n",
    "    # print(f\"pNN50:{feat_pnn50}\")\n",
    "    #The proportion of NN20 divided by total number of NNs(pNN20)\n",
    "    features.append(hrv_class.pNN20(r_peaks_pan))\n",
    "    # print(f\"pNN20:{feat_pnn20}\")\n",
    "    features.extend([ecg_fft['fft_peak'][0], ecg_fft['fft_peak'][1], ecg_fft['fft_peak'][2], ecg_fft['fft_norm'][0],\n",
    "                     ecg_fft['fft_norm'][1], ecg_fft['fft_ratio'], ecg_fft['fft_total']])\n",
    "    #The\n",
    "    \n",
    "    df.loc[index] = features\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features from all signals and write to a csv file\n",
    "def get_ecgfeatures(ecg, fs, subject, label, df):\n",
    "    ecg = td.ecg(ecg, interactive= False, show = False, sampling_rate=700)\n",
    "    rpeaks = ecg['rpeaks']\n",
    "    filtered_ecg = ecg['filtered']\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(filtered_ecg)\n",
    "    plt.plot(rpeaks,filtered_ecg[rpeaks], 'ro')\n",
    "    df_features = get_features(rpeaks, fs, df, subject+str(label))\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features.head()\n",
    "# print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Respiration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs =700\n",
    "# subject ='S20'\n",
    "# df_ecg = read_from_csv('ecg_1.csv')\n",
    "# ecg =df_ecg[subject]\n",
    "\n",
    "# filtered_ecg = filter_signal(ecg, fs)\n",
    "# rpeaks, info = nk.ecg_peaks(ecg, sampling_rate=fs)\n",
    "# ecg_rate = nk.ecg_rate(rpeaks, sampling_rate=fs, desired_length=len(ecg))\n",
    "# edr = nk.ecg_rsp(ecg_rate, sampling_rate=fs)\n",
    "# resp_peaks1, _ = signal.find_peaks(edr, height=0, distance=4)\n",
    "# nk.signal_plot(edr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.interpolate import splrep, splev\n",
    "\n",
    "# fs =700\n",
    "# subject ='S20'\n",
    "# df_ecg = read_from_csv('ecg_1.csv')\n",
    "# ecg =df_ecg[subject]\n",
    "# ecg_td = td.ecg(ecg, interactive= False, show = False, sampling_rate=700)\n",
    "# rr = ecg_td['rpeaks']\n",
    "# filtered_ecg = ecg_td['filtered']\n",
    "\n",
    "# fs = 700\n",
    "# # rr = rpeaks\n",
    "# rr = (rr / fs) * 1000\n",
    "# rri = np.diff(rr)\n",
    "# print(rri)\n",
    "\n",
    "# def interp_cubic_spline(rri, sf_up=4):\n",
    "#     rri_time = np.cumsum(rri) / 1000.0\n",
    "#     time_rri = rri_time - rri_time[0]\n",
    "#     time_rri_interp = np.arange(0, time_rri[-1], 1 / float(sf_up))\n",
    "#     tck = splrep(time_rri, rri, s=0)\n",
    "#     rri_interp = splev(time_rri_interp, tck, der=0)\n",
    "#     return rri_interp\n",
    "\n",
    "# sf_up = 4\n",
    "# rri_interp = interp_cubic_spline(rri, sf_up) \n",
    "# hr = 1000 * (60 / rri_interp)\n",
    "# print('Mean HR: %.2f bpm' % np.mean(hr))\n",
    "\n",
    "# # Detrend and normalize\n",
    "# edr = signal.detrend(hr)\n",
    "# edr = (edr - edr.mean()) / edr.std()\n",
    "\n",
    "# # Find respiratory peaks\n",
    "# resp_peaks, _ = signal.find_peaks(edr, height=0, distance=sf_up)\n",
    "\n",
    "# # Convert to seconds\n",
    "# resp_peaks = resp_peaks\n",
    "# resp_peaks_diff = np.diff(resp_peaks) / sf_up\n",
    "\n",
    "# # Plot the EDR waveform\n",
    "# plt.plot(edr)\n",
    "# plt.plot(resp_peaks, edr[resp_peaks], 'o')\n",
    "# _ = plt.title('ECG derived respiration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visual comparison\n",
    "# df_resp = read_from_csv('resp_1.csv')\n",
    "# resp=df_resp[subject]\n",
    "\n",
    "# # rpeaks, info = nk.ecg_peaks(resp, sampling_rate=fs)\n",
    "# resp_peaks2, _ = signal.find_peaks(resp, height=2, distance=30)\n",
    "# maxi = 0\n",
    "# begini = 0\n",
    "# peaks = []\n",
    "\n",
    "# for i in range(len(resp_peaks2)):\n",
    "#     if resp_peaks2[i] >= resp_peaks2[begini] + 400:\n",
    "#         begini = i\n",
    "#         peaks.append(resp_peaks2[maxi])\n",
    "#         maxi = i\n",
    "\n",
    "#     if resp[resp_peaks2[i]]> resp[resp_peaks2[maxi]]:\n",
    "#         maxi = i\n",
    "\n",
    "# print(peaks)\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.plot(resp)\n",
    "# plt.plot(peaks, resp[peaks], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(resp_peaks1),len(resp_peaks2))\n",
    "\n",
    "# print(peaks)\n",
    "# print(resp_peaks1, resp_peaks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(y), df_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df_features, y, test_size=0.3, random_state=4)\n",
    "# scaler = StandardScaler().fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score=[]\n",
    "# print(df_features.shape)\n",
    "# for i in range (1,50):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df_features, y, test_size=0.3, random_state=i)\n",
    "#     scaler = StandardScaler().fit(X_train)\n",
    "#     X_train = scaler.transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "#     pca = PCA(n_components=7)\n",
    "#     pca.fit(X_train)\n",
    "#     X_train = pca.transform(X_train)\n",
    "#     X_test = pca.transform(X_test)\n",
    "#     model = LogisticRegression()\n",
    "#     model.fit(X_train, y_train)\n",
    "#     score.append(model.score(X_test, y_test))\n",
    "# print(score)\n",
    "# print(np.mean(score))\n",
    "# #7 components gives an accuracy of 83.5%#nt(np.skew)wirite a code that can detect stress from ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=4) \n",
    "# pca = pca.fit(X_train)\n",
    "\n",
    "# X_train_pca=pca.transform(X_train)\n",
    "# X_test_pca=pca.transform(X_test)\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.scatter(X_train_pca[:,0], X_train_pca[:,1], c=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression()\n",
    "# model.fit(X_train_pca, y_train)\n",
    "# print(model.score(X_test_pca, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,4))\n",
    "# plt.plot(filtered_ecg)\n",
    "# plt.plot(r_peaks_pan,filtered_ecg[r_peaks_pan], 'ro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecg_td = td.ecg(ecg, interactive= False, show = False, sampling_rate=700)\n",
    "# t = ecg_td['ts']\n",
    "\n",
    "# plt.figure(figsize=(12,4))\n",
    "# rpeaks = ecg_td['rpeaks']\n",
    "# filtered_signal = ecg_td['filtered']\n",
    "# plt.plot(filtered_signal)\n",
    "# plt.plot(rpeaks,filtered_signal[rpeaks], 'ro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hrv_class = HRV(fs)\n",
    "# print(td.hr_parameters(rpeaks = t[rpeaks]))\n",
    "# print(hrv_class.HR(rpeaks))\n",
    "# print(np.mean(hrv_class.HR(rpeaks)))\n",
    "\n",
    "# print(td.hr_parameters(rpeaks = t[rpeaks]))\n",
    "# print(hrv_class.HR(r_peaks_pan))\n",
    "\n",
    "# print(td.nn20(rpeaks = t[rpeaks]))\n",
    "# print(hrv_class.NN20(rpeaks))\n",
    "# print(hrv_class.pNN20(rpeaks))\n",
    "# print(td.nn50(rpeaks = t[rpeaks]))\n",
    "# print(hrv_class.NN50(rpeaks))\n",
    "# print(hrv_class.pNN50(rpeaks))\n",
    "\n",
    "# print(td.rmssd(rpeaks=t[rpeaks]))\n",
    "# print(hrv_class.RMSSD(rpeaks))\n",
    "\n",
    "# print(td.sdnn(rpeaks=t[rpeaks]))\n",
    "# print(hrv_class.SDNN(rpeaks))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
