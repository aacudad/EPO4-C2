{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(features)\n",
    "X_train = scaler.transform(features)\n",
    "\n",
    "pca = PCA(n_components=25)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "x_train = X_train_pca[:,0:3] # Three best features\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x_train[:,0], x_train[:,1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform pca on features\n",
    "plt.bar(range(0,25), pca.explained_variance_ratio_, label=\"individual var\");\n",
    "plt.step(range(0,25), np.cumsum(pca.explained_variance_ratio_),'r', label=\"cumulative var\");\n",
    "plt.xlabel('Principal component index'); plt.ylabel('explained variance ratio %');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information gain\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "%matplotlib inline\n",
    "\n",
    "scaler = StandardScaler().fit(features)\n",
    "X_train = scaler.transform(features)\n",
    "\n",
    "importances = mutual_info_classif(X_train, y)\n",
    "feat_importances = pd.Series(importances, features.columns[0:len(features.columns)])\n",
    "feat_importances.plot(kind='bar', color='teal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_features_index = []\n",
    "\n",
    "for a in total_features:\n",
    "    total_features_index.append(a)\n",
    "\n",
    "print(total_features_index)\n",
    "print(len(total_features_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Threshold\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "scaler = StandardScaler().fit(total_features)\n",
    "X_train = scaler.transform(total_features)\n",
    "X = X_train[0:,0:49]\n",
    "\n",
    "v_threshold = VarianceThreshold(threshold=0)\n",
    "v_threshold.fit(X)\n",
    "index = v_threshold.get_support()\n",
    "true_index = [i for i, x in enumerate(index) if x]\n",
    "\n",
    "# for i in true_index:\n",
    "#     print(total_features_index[i])\n",
    "#     print(total_features[total_features_index[i]])\n",
    "vt_features = [total_features_index[i] for i in true_index]\n",
    "features = total_features[vt_features]\n",
    "# features.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson Correlation\n",
    "import seaborn as sns\n",
    "\n",
    "# total_features = pd.merge(edafeatures, ecgfeatures, left_index=True, right_index=True)\n",
    "out_features = total_features\n",
    "out_features['y'] = y\n",
    "# plt.figure(figsize=(12,10))\n",
    "cor = out_features.corr()\n",
    "# print(cor)\n",
    "# sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "# plt.show()\n",
    "#Correlation with output variable\n",
    "cor_target = abs(cor[\"y\"])\n",
    "\n",
    "# print(cor_target)\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.3]\n",
    "# features = out_features[relevant_features.index[:-1]]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HR_mean, scr_mobility scr_integral \n",
    "print(out_features[['HR_mean',\"scr_mobility\"]].corr())\n",
    "print(out_features[[\"HR_mean\",\"scr_integral\"]].corr())\n",
    "print(out_features[[\"scr_mobility\",\"scr_integral\"]].corr())\n",
    "# features = features[['HR_mean',\"scr_mobility\",\"scr_integral\"]]\n",
    "features = out_features[[\"HR_mean\", \"scr_mobility\", \"scr_integral\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Forward wrapper\n",
    "\n",
    "# from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "# ffs = SequentialFeatureSelector(total_features, k_features='best', forward = 'True', n_jobs=-1)\n",
    "# ffs.fit(X, y)\n",
    "# features= list(ffs.k_feature_names_)\n",
    "# features= list(map(int, features))\n",
    "# lr.fit[x_train[features], y_train]\n",
    "# y_pred = lr.predict(x_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backwards\n",
    "import statsmodels.api as sm\n",
    "\n",
    "cols = list(total_features.columns)\n",
    "pmax = 1\n",
    "\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = total_features[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)\n",
    "features = total_features[selected_features_BE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper Forwards\n",
    "sfs = SFS(svm.SVC(),\n",
    "          k_features=6,\n",
    "          forward=True,\n",
    "          floating=False,\n",
    "          scoring = 'r2',\n",
    "          cv = 0)\n",
    "sfs.fit(X, y)\n",
    "feature_namesf = list(sfs.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper Backwards\n",
    "sbs = SFS(svm.SVC(),\n",
    "         k_features=6,\n",
    "         forward=False,\n",
    "         floating=False,\n",
    "         cv=0)\n",
    "sbs.fit(X, y)\n",
    "feature_namesb = list(sbs.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step-wise wrapper\n",
    "sffs = SFS(svm.SVC(),\n",
    "         k_features=(3,11),\n",
    "         forward=True,\n",
    "         floating=True,\n",
    "         cv=0)\n",
    "sffs.fit(X, y)\n",
    "feature_namess = list(sffs.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "fig1 = plot_sfs(sfs.get_metric_dict(), kind='std_dev')\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = total_features[feature_namess]\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = features\n",
    "alphas = np.logspace(-4, -0.5, 5)\n",
    "\n",
    "out_k_fold = KFold(3, shuffle=False)\n",
    "in_k_fold = KFold(3, shuffle=False)\n",
    "for (calib, test) in out_k_fold.split(X, y):\n",
    "    X_calib, y_calib = X[calib[0]:calib[-1]], y[calib[0]:calib[-1]]\n",
    "    X_test, y_test = X[test[0]:test[-1]], y[test[0]:test[-1]]\n",
    "    lasso_cv = LassoCV(alphas=alphas, random_state=0, max_iter=10000, cv=in_k_fold)\n",
    "    lasso_cv.fit(X_calib, y_calib)\n",
    "    print(lasso_cv.alpha_, lasso_cv.score(X_test, y_test))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sel_ = SelectFromModel(\n",
    "    LogisticRegression(C=0.5, penalty='l1', solver='liblinear', random_state=10))\n",
    "sel_.fit(scaler.transform(X_train), y_train)\n",
    "\n",
    "a =(sel_.estimator_.coef_ == 0).ravel().tolist()\n",
    "\n",
    "# removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "X_train_selected = sel_.transform(scaler.transform(X_train))\n",
    "X_test_selected = sel_.transform(scaler.transform(X_test))\n",
    "# selected_columns_lasso = logistic.columns[selected_featuress.var() != 0]\n",
    "\n",
    "# Y_test_pred = logistic_model.predict(X_test)\n",
    "# log_score = logistic_model.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
